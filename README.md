# News Aggregator

A modern news aggregation system built with Python, featuring real-time scraping, PostgreSQL storage, and a Flask web interface.

## ğŸš€ Features

- Real-time news scraping with intelligent rate limiting
- PostgreSQL database with optimized schema
- Modern web interface built with Flask and Bootstrap
- Category-based news organization
- Responsive design for all devices
- Error handling and retry mechanisms
- Logging system for monitoring and debugging

## ğŸ›  Tech Stack

- **Backend**: Python 3.9+
- **Web Framework**: Flask 3.0
- **Database**: PostgreSQL 15
- **Scraping**: BeautifulSoup4, Requests
- **Frontend**: Bootstrap 5.3
- **Container**: Docker & Docker Compose
- **Development**: Poetry (dependency management)

## ğŸ“‹ Prerequisites

- Python 3.9 or higher
- Docker and Docker Compose
- PostgreSQL 15 or higher

## ğŸ”§ Installation

1. Clone the repository:
```bash
git clone https://github.com/eraybulut34/news-aggregator.git
cd news-aggregator
```

2. Create and activate virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: .\venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Start PostgreSQL with Docker:
```bash
docker-compose up -d
```

## ğŸš€ Usage

1. Run the scraper to collect news:
```bash
python scraper.py
```

2. Start the web application:
```bash
python app.py
```

3. Visit `http://localhost:5001` in your browser

## ğŸ— Project Structure

```
news-aggregator/
â”œâ”€â”€ app.py              # Flask application
â”œâ”€â”€ scraper.py         # News scraping logic
â”œâ”€â”€ requirements.txt   # Project dependencies
â”œâ”€â”€ docker-compose.yml # Docker configuration
â”œâ”€â”€ README.md         # Project documentation
â””â”€â”€ templates/        # HTML templates
    â”œâ”€â”€ index.html    # Home page template
    â””â”€â”€ detail.html   # News detail template
```

## ğŸ”„ Database Schema

```sql
CREATE TABLE news (
    id SERIAL PRIMARY KEY,
    title TEXT,
    content TEXT,
    url TEXT UNIQUE,
    image_url TEXT,
    category TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

## ğŸ›¡ Error Handling

- Automatic retry mechanism for database connections
- Graceful handling of scraping failures
- Rate limiting to prevent server overload
- Comprehensive logging system

## ğŸ“ Logging

The application uses Python's built-in logging system with the following features:
- Log levels: INFO, ERROR
- Timestamp and log level in each message
- Separate logging for scraping and database operations

## ğŸ”’ Security

- SQL injection prevention using parameterized queries
- User-Agent rotation for scraping
- Environment variable based configuration
- No sensitive data in version control

## ğŸš§ Future Improvements

- [ ] Add user authentication system
- [ ] Implement news search functionality
- [ ] Add API endpoints for mobile applications
- [ ] Implement caching system
- [ ] Add test coverage
- [ ] Set up CI/CD pipeline

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request. 
